{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"https://th.bing.com/th/id/OIP.r52YfArYRzzWARjK5nGk3wHaDi?pid=ImgDet&amp;rs=1\" style=\"float:left; height:110px; width:180px\" />&nbsp; &nbsp; &nbsp; &nbsp; Stream Processing and Analytics (S1-23_DSEOGZG556)</p>\n",
    "\n",
    "<h4><strong>&nbsp; &nbsp; &nbsp; Assignment - </strong><strong>Architecture and Stream processing using Samza</strong></h4>\n",
    "\n",
    "<p><strong>&nbsp; &nbsp; &nbsp; &nbsp;Group-G6</strong></p>\n",
    "\n",
    "<table align=\"left\" border=\"1\">\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "\t\t\t<td><strong>Student ID</strong></td>\n",
    "\t\t\t<td><strong>Name</strong></td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>2022OG04032</td>\n",
    "\t\t\t<td>PATEL, SUMANTA KUMAR</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>2022OG04006</td>\n",
    "\t\t\t<td>PATI, SOUMYA RANJAN</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>2022OG04030</td>\n",
    "\t\t\t<td>PONNEKANTI, JYOTHSNA RAJESWARI</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>2022OG04025</td>\n",
    "\t\t\t<td>PUNEET</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td>2022OG04054</td>\n",
    "\t\t\t<td>RASTOGI, ANAND</td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://samza.apache.org/learn/documentation/1.6.0/core-concepts/core-concepts.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"background-color:DodgerBlue; color:black\"><b>Problem Statement:</b></h5>\n",
    "<p align=\"justify\">The e-commerce platform receives a massive amount of data, including customer interactions, product updates, and order information. The platform needs to process this data in real-time and make timely decisions based on it. However, the existing system is unable to handle the increasing data volume and latency requirements. Therefore, the organization decides to adopt Apache Samza to address these challenges.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"background-color:DodgerBlue; color:black\"><b>Abstract and high level details of architecture:</b></h5>\n",
    "\n",
    "The architecture consists of the following components:\n",
    "\n",
    "<p align=\"justify\">(a) Data Sources: The e-commerce platform collects data from various sources, such as user interactions, inventory updates, and payment gateways. These sources generate a continuous stream of events that need to be processed.</p>\n",
    "\n",
    "<p align=\"justify\">(b) Apache Kafka: Samza relies on Apache Kafka as the messaging system to handle data ingestion and distribution. Kafka provides fault-tolerant and scalable message queues for reliable data transfer.</p>\n",
    "\n",
    "<p align=\"justify\">(c) Samza Job: A Samza job represents a logical unit of processing that consumes input messages from Kafka, performs computations, and produces output messages to Kafka or external systems. Multiple Samza jobs can run concurrently to process different aspects of the data.</p>\n",
    "\n",
    "<p align=\"justify\">(d) Samza Stream Processor: Samza Stream Processor (SSP) is the runtime component responsible for executing Samza jobs. It manages the deployment, scaling, and fault tolerance of job instances across a cluster of machines.</p>\n",
    "\n",
    "<p align=\"justify\">(e) State Stores: Samza provides local and distributed state stores for maintaining intermediate and final results during processing. These stores enable efficient stateful computations and fault-tolerant recovery.</p>\n",
    "\n",
    "<p align=\"justify\">(f) Output Sinks: Processed data can be sent to various output sinks, such as databases, caches, or external APIs, depending on the business requirements.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"background-color:DodgerBlue; color:black\";><b>Implementation Steps:</b></h4>\n",
    "\n",
    "<h5 style=\"color:cyan\">Here is a step-by-step guide to implementing Samza's architecture for the e-commerce platform:</h5>\n",
    "\n",
    "<p align=\"justify\">(a) Identify Data Sources: Determine the data sources that need to be processed in real-time. This could include user events, product updates, or order information.</p>\n",
    "\n",
    "<p align=\"justify\">(b) Define Samza Jobs: Design Samza jobs to handle different aspects of data processing, such as user behavior analysis, inventory management, or fraud detection. Each job should have well-defined input and output message formats.</p>\n",
    "\n",
    "<p align=\"justify\">(c) Configure Kafka: Set up a Kafka cluster to handle data ingestion and distribution. Configure topics to partition and replicate data for fault tolerance and scalability.</p>\n",
    "\n",
    "<p align=\"justify\">(d) Implement Samza Jobs: Write the business logic for each Samza job using Samza's API. Define the necessary transformations, aggregations, or filters to process the input messages. Utilize state stores for maintaining intermediate results and external dependencies for integration with external systems.</p>\n",
    "\n",
    "<p align=\"justify\">(e) Deploy Samza Jobs: Package the Samza jobs and deploy them to the Samza cluster. Configure the necessary resources, such as CPU, memory, and network, for each job instance. Monitor the jobs' health and performance using Samza's monitoring tools.</p>\n",
    "\n",
    "<p align=\"justify\">(f) Test and Iterate: Validate the Samza implementation by feeding simulated data and verifying the correctness of the output. Fine-tune the job configurations and scale up the cluster based on performance requirements.</p>\n",
    "\n",
    "<p align=\"justify\">(g) Monitor and Maintain: Monitor the Samza cluster for any issues, such as job failures, resource bottlenecks, or data inconsistencies. Perform regular maintenance tasks, such as upgrading Samza or Kafka versions, optimizing job configurations, and monitoring system health.</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"background-color:DodgerBlue; color:black\";><b>Architectural   diagram for SAMZA side:</b></h4>\n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(1)\tE-commerce Platform:</strong> This represents the main business application or platform that requires real-time data processing. It could be an e-commerce website, mobile app, or any other system that deals with customer interactions, product updates, and order information.\n",
    "</p>\n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(2)\tData Sources:</strong> These are the various sources that generate the data to be processed, such as user interactions, inventory updates, or payment gateways. These sources continuously produce a stream of events.\n",
    "</p>\n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(3)\tKafka:</strong> Apache Kafka is used as the messaging system to handle data ingestion and distribution. It acts as a buffer between the data sources and the Samza jobs, providing reliable, scalable, and fault-tolerant message queues.\n",
    "</p>\n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(4)\tSamza Jobs:</strong> Samza jobs represent the logical units of processing. Each job consumes input messages from Kafka, performs computations, and produces output messages. Multiple Samza jobs can run concurrently to process different aspects of the data, such as user behavior analysis, inventory management, or fraud detection.\n",
    "</p>\n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(5)\tData Processing:</strong> This represents the actual processing of the data within the Samza jobs. The jobs can perform various operations, including filtering, aggregating, transforming, or enriching the input data to derive meaningful insights and make real-time decisions.\n",
    "</p>\n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(6)\tOutput Sinks:</strong> These are the destinations where the processed data is sent for further analysis or integration with external systems. Examples of output sinks include databases, caches, or external APIs. The processed data can be used for generating reports, updating inventory, triggering notifications, or any other business-specific requirements.\n",
    "</p>\n",
    "<p align=\"justify\" style=\"color: cyan;\"><i>The diagram illustrates how Apache Samza's architecture enables the e-commerce platform to process data from various sources in real-time, perform computations, and deliver the processed data to output sinks for further analysis or action.</i></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Picture1.png\" style=\"float:center; height:800px; width:600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"background-color:DodgerBlue; color:black\";><b>Language/Programming/Implementation Details:</b></h4>  \n",
    "   \n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(1) Apache Kafka:</strong> Apache Kafka is used as the messaging system for data ingestion and distribution. It is a distributed streaming platform that provides high-throughput, fault-tolerant, and scalable messaging.\n",
    "</p>  \n",
    "   \n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(2) Samza API:</strong> Samza provides an API for implementing stream processing jobs. It is typically used with Java or Scala programming languages. The API allows developers to define transformations, aggregations, and filters on the input stream of messages.\n",
    "</p>\n",
    "   \n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(3) State Stores:</strong> Samza provides local and distributed state stores for maintaining intermediate and final results during processing. These stores are used for efficient stateful computations and fault-tolerant recovery.\n",
    "</p>\n",
    "   \n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(4) External Dependencies:</strong> Samza jobs can integrate with external systems, such as databases, caches, or external APIs, to read or write data. These dependencies can be configured and accessed within the Samza job implementation.\n",
    "</p>\n",
    "\n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(5) Deployment and Scaling:</strong> Samza jobs are deployed to a cluster of machines, managed by the Samza Stream Processor (SSP). The SSP handles the deployment, scaling, and fault tolerance of job instances across the cluster.\n",
    "</p>\n",
    "\n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(6) Monitoring and Maintenance:</strong> Samza provides monitoring tools to monitor the health and performance of the jobs and the cluster. Regular maintenance tasks, such as upgrading Samza or Kafka versions, optimizing job configurations, and monitoring system health, should be performed to ensure smooth operation.\n",
    "</p>\n",
    "\n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(7) Testing and Validation:</strong> The Samza implementation should be thoroughly tested using simulated data to ensure the correctness of the output. Testing should cover various scenarios and edge cases to validate the behavior of the jobs.\n",
    "</p>  \n",
    "\n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(8) Resource Configuration:</strong> The resources, such as CPU, memory, and network, should be configured appropriately for each Samza job instance based on its requirements. Resource allocation should be optimized to achieve the desired performance and scalability.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"background-color:DodgerBlue; color:black\";><b>Here's an example of a programming implementation for the Samza architecture using Java:</b></h5>  \n",
    "   \n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(1) Define Data Sources:</strong> Identify the data sources that need to be processed in real-time, such as user events, product updates, or order information.\n",
    "</p>  \n",
    "   \n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(2) Set up Apache Kafka:</strong> Install and configure Apache Kafka to handle data ingestion and distribution. Create topics to partition and replicate data for fault tolerance and scalability.</p>\n",
    "   \n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(3) Implement Samza Jobs:</strong> Write the business logic for each Samza job using the Samza API. Here's an example of a Samza job that processes user events:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```java\n",
    "public class UserEventProcessor implements StreamTask, InitableTask {  \n",
    "  \n",
    "    private KeyValueStore<String, Integer> userCountStore;  \n",
    "  \n",
    "    @Override  \n",
    "    public void init(Config config, TaskContext context) throws Exception {  \n",
    "        // Initialize state store  \n",
    "        userCountStore = (KeyValueStore<String, Integer>) context.getStore(\"user-count-store\");  \n",
    "    }  \n",
    "  \n",
    "    @Override  \n",
    "    public void process(IncomingMessageEnvelope envelope, MessageCollector collector, TaskCoordinator coordinator) throws Exception {  \n",
    "        // Process user event  \n",
    "        UserEvent userEvent = (UserEvent) envelope.getMessage();  \n",
    "        String userId = userEvent.getUserId();  \n",
    "  \n",
    "        // Update user count in state store  \n",
    "        Integer count = userCountStore.get(userId);  \n",
    "        if (count == null) {  \n",
    "            count = 1;  \n",
    "        } else {  \n",
    "            count++;  \n",
    "        }  \n",
    "        userCountStore.put(userId, count);  \n",
    "  \n",
    "        // Emit processed event  \n",
    "        collector.send(new OutgoingMessageEnvelope(new SystemStream(\"kafka\", \"processed-events\"), userEvent));  \n",
    "    }  \n",
    "}  \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(4) Configure Samza Job:</strong> Create a configuration file to specify the input and output streams, state stores, and other job-specific settings. Here's an example configuration file:\n",
    "</p>\n",
    "\n",
    "```properties  \n",
    "job.name=user-event-processor  \n",
    "job.coordinator.factory=org.apache.samza.zk.ZkJobCoordinatorFactory  \n",
    "task.inputs=kafka.user-events  \n",
    "task.output=kafka.processed-events  \n",
    "stores.user-count-store.factory=org.apache.samza.storage.kv.RocksDbKeyValueStoreFactory  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(5) Deploy Samza Job:</strong> Package the Samza job and its dependencies into a JAR file. Deploy the JAR file to the Samza cluster and start the job using the following command:</p>\n",
    "\n",
    "```bash\n",
    "./run-job.sh --config-factory=org.apache.samza.config.factories.PropertiesConfigFactory --config-path=config.properties \n",
    "```\n",
    "\n",
    "<p align=\"justify\">\n",
    "<strong style=\"color:cyan\";>(6) Monitor and Maintain:</strong> Monitor the Samza cluster using tools like Samza's built-in monitoring or third-party monitoring solutions. Perform regular maintenance tasks, such as upgrading Samza or Kafka versions, optimizing job configurations, and monitoring system health.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5 style=\"background-color:DodgerBlue; color:black\";><b>Mention the commands to be used as part of streaming integration with other platforms if applicable.</b></h5>\n",
    "\n",
    "<em>To integrate Samza with other platforms for streaming data processing, you can use various commands and tools depending on the specific integration requirements. Here are some common commands and tools used for integration:</em>  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
